08 January 2019
Added code to lookup latitude in districts file and add district and municipality information
07 January 2019
Added code to work out age of input file
03 January 2019
Added menu to choose type of filter
02 January 2019
Minor changes to use xls file as source file
31 December 2018
Edited code to deal with new conversion script from Lukáš
And fixed problem with csv stripping out data from timestamp field by using xls file
20 December 2018
Lukas changed his script and now it includes the country code that I need.
Changed addextradata function to use this data and also moved the country filter to after the processing to limit output
18 December 2018
Changed data processing from using .map to .merge. Quicker and accurate
Also added set of 3 letter codes.
Need to look at field names and duplicate columns in the merge
18 December 2018
Updated country info file
Now need to change lookup for city and peak time to use 3 letter codes
17 December 2018
Pivot table is better
Next step is to update country info to
17 December 2018
Problem with adding column was using wrong timestamp data in log file - fixed.
Next step : fix pivot table to use new codes and also country data and clean up code
16 December 2018
Trying to add new column but getting index issue. May be a datatype issue.
15 December 2018
created parsing code to produce dataframe of timestamp:countrycode information
next step add new column to main data with REAL country codes
17 December 2018
15 December 2018
Added latest data from 14 December 2018 and log files from 14 December 2018
Next step find country codes
17 December 2018
14 December 2018
Was working on getting 3 letter country codes but Diego is modifying the script
Tidied up code to comment out unused.
Next step is to look at presenting data
13 December 2018
Added code to create pivot file
Updated constants to include Tel Aviv, Israel
11 December 2018
Added option to export pivot file
Next step : remove old non-pandas code
10 December 2018
Added export to csv option to option 7 in menu.
09 December 2018
Added peak test
next step is to output to csv
09 December 2018
Working on using pandas to do everything with some success
Next step calculate peak column
08 December 2018
Created menu so that once the output file is created I can work on analysing without repeating file creation
07 December 2018
Successfully processed data using pandas and exported pivot results to csv.
Checked these with the sample data and get good correlation.
However, this is summary data for detailed i.e. city/peak/connection type.
Need to also produce summary for high level (all country, all city, etc. ).
todo find a way to produce all possible variations in panda.
06 December 2018
Used pandas to generate pivot tables
Next step, finish data preparation by using hour to determine peak or off peak
05 December 2018
Moved code for adding peak / city data to module
Next step add peak true/false
05 December 2018
Using real data there is a correlation between my coded results for in city radius and source data.
Next step is to do the same for peak/ off peak
05 December 2018
Added code to test if result is in city and tested with hard-coded data
Next step is to use real data
02 December 2018
Created project to work on ME data results
Added sample csv files